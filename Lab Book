## Tuesday 10/10/23
Today was my first day in the lab. I had previously developed a SIR model, based on Gillespe's direct method. I had included births and deaths at the same rate, however due to time
constraints it was decided to set mu=0. I developed a few tests for the model (based on P of extinctions and final epidemic sizes) which the model passed. These looked to see whether
the model roughly met the deterministic outcomes for a range of parameters. The model passed all the tests. Seed used was 1690. Librairies used include numpy, Pymc, Arviz and pyplot. Numpy had to
be rolled back to 1.5.2 in order to allow PyMC to function, as I ran into issues with that library.

## Thursday 12/10/23
I started the day continuing from Tuesday. My ambition at the start of the day was to get a few ABC models set up and running. The first task was to restructure the SIR model to return
the times as well as X in one numpy array, so that I could give the model one piece of obversed data. However, there were issues with the SIR function, which took the day to solve. The
solution was in fixing the length of the output array of the SIR model.

## Tuesday 17/10/23
Today I fixed the issues left over from last day and fitted my first model. It took ~30 mins to run, however optimisation has been able to reduce this. The plan is to fit a series of models
at neutral resolution, and then at 5 lower resolutions: X1,X10,X100. The plan is to fit 10 of each model initially. The change in resolution will be by starting with a lower value of N,
and then scaling the output of the SIR model up to the neutral resolution. This should generate good initial plots etc.

## Thursday 19/10/23
Today I began by writing a script that will generate trajectory data by changing the initial seed. I will use seeds 1-10 for the 10 trajectories.

##Tuesday 24/10/23
Meeting with Nik: Gamma may not be hugely impactful. Keep an eye on how the data actually fits as well/consider other metrics e.g., time to get started. Fix the mean by switching to the mode 
for the probability distribution. Also check each run against the maximum likelihood estimate. Next steps: learn how to use the HBC. Look at how quantisation changes the epidemic based on extinctions.
Start using controls on the model. Then consider how reducing the proportional epidemic load impacts the model @ full N.

##Thursday 26/10.23
I refitted the models with correct X0 values and used the mode instead of the mean for my posterior estimate. I also wrote and tested a MLE function, and generated a set of new plots.

##Tuesday 31/10/23
I met with Rachel to discuss next steps and the parameter fitting. We came up with a multipoint plan of next tasks. There are as follows:
1. Look @ paired t-test with MLE estimates and N=1000 parameter estaimtes
2. Look @ Traj 1,5,6 as they were outliers regarding gamma. Investigate the PyMC function and what output data it gives.
3. Refit Trajs with a fixed gamma
4. Set I(0)= 1 for all resolution and fit.
5. Look @ final epidemic sizes/extinction proportions for all fitted parameter values. Run 1000 simulations for each.
6. Add a series of controls: Scale beta; add another gamma parameter; do a fixed cull @ certain timesteps.

## Tuesday 7/11/23
I have continued to work on the 6th above objectives. 1,3,5 and 6 are finished. 2 is harder as the ABC used is based on a more matheamtically involved method that is harder to detect issues for.
However, N=10 had incredibly low acceptance rates. By fitting with a function that repeats the simulation (up to 10 times) if an early extinction occurs, I hope to increase the stability of N=10.

## Tuesday 14/11/23
Continued to work on model fitting. There were issues with the convergence of I(0)=1. I carried out the no-extinction "fix", unified the code and ran inital simulations to see how variation in N changes
simulation results. The main effect was increasing extinction as N decreases, and increased variance

## Tuesday 23/11/23
I had a meeting with Nik regarding next steps where I presented the work completed up until now. He saw the issues with PyMC fitting, and suggested I build a simple ABC rejection algorithim. I built the algorithim
in the afternoon.

## Thursday 25/11/23
Built a simple metapopulation model

## Tuesday 30/11/23
I used the built ABC model to fit some initial epidemic trajectories. I fitted Splines to the normalised proportion of accepted runs at different distance thresholds.

## Thursday 2/12/23
Final meeting of term with Nik. We agreed that the cluster was to be used to brute force the rejection ABC to parameterise my models.
A full list of objectives is found below:
1. Produce better Splines to charaterise the thresholded ABC curves
2. Fit with wider values of beta- Nik suggested sampling from an exponential distribution
3. Make cumulative distance graphs
4. Investigate better distance metrics
5. When all above is working, normalise the parameter distributions and sample from them for the simulations
6. Expand on the metapopulation model and apply all above to it.
7. Run with I(0)=1

## Friday 12/01/23
Back working on the project. Over the holidays I learnt to use the University's HPC and fitted the ABC trajectories on it. The only complicaton is the N=10 run failing to reach 0 by 10, which was the new upper value I choose for
the beta prior distribution. I shall have to expand the range further.
I investigated 4 above, and found the current measure to be the best. I considered a combination of times and final sizes, but to no avail. I drew up a function for 5 which samples rather effectively from under the curve. I have run the epidemics
with I(0)=1 and initially with the metapopulations.
I need to work on mle for metapopulations and for N=10 natively, to prove the proposistion that N=10 will naturely have a wider distribution for both mle and ABC.
I then need to use my sampled distribution to run simulations. Some mock plots would be good.
Of course the write up! I will try to write the methods section on Sunday and discuss the rest with Nik next week.
